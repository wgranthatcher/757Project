BASIC ML RESULTS
Apparel1000
        customer_id  product_id  product_parent  helpful_votes  total_votes   vine  verified_purchase
count  9.990000e+02  999.000000    9.990000e+02     999.000000   999.000000  999.0         999.000000
mean   2.124015e+07  401.311311    4.622964e+08       1.439439     1.744745    0.0           0.428428
std    1.643357e+07  235.878387    3.000373e+08       7.352565     7.887480    0.0           0.495099
min    2.361900e+04    0.000000    2.933340e+05       0.000000     0.000000    0.0           0.000000
25%    6.057116e+06  205.000000    2.037715e+08       0.000000     0.000000    0.0           0.000000
50%    1.755057e+07  399.000000    4.474635e+08       0.000000     0.000000    0.0           0.000000
75%    3.645551e+07  604.500000    7.466546e+08       1.000000     1.000000    0.0           1.000000
max    5.308514e+07  826.000000    9.976209e+08     148.000000   150.000000    0.0           1.000000
Class Attribute: helpful_votes
---- Decision Tree Entropy ----
DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')
[ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  1  0  0  3  0
  0  1  1  0  1  1  4  1  0  0  0  0  1 29  0  0  0  9  0  0  0  0  0  0
  1  0  0  0  0  0  0  0 29  2  0  0  1  0  0  1  2  0  0  6  0  3  0  0
  0  1  3  5  1  0  0  0  0  0  1  0  0  0  0  1  1  6  3  0  0  0  0  0
  2  2  9  0  5  0  2  0  0  4 15  0  0  0  1  1  0  0  6 29  0  0  0  0
  0 12  0  0  0  0  0  6  3  0  4  0  1  0  0  0  0  0  0  3  0  0  1  0
  0  0  1  0  0  0  0  0  0  0  0  0  2  0  0  0  0  3  1  0  0  0  0  1
  1  3  0  1 32  3  0  1  3  0  0  0  0  0  0  0  1  0  1  0  0  1  0  0
  0  1  0  0  0  0  0  1  0  1  0  0  0  0  0  0  6  3  3  0  0  0  0  4
  0  0  0  0  0  3 21  0  0  0  0  0  0  0  0  1  3  0  8  0  0  0  0  0
  0  0  1  1  0  3  0 32  1  3  1 12  0  0  0  0  0  0  0  0  0  0  0  0
  0  1  2  0  1  1  1  0  2  1  0  0  0  6  0  6  9  2  1 32  1  0  3  3
  0  0  0  0  0  0  3  0  4  0  0  0]
DT Entropy Accuracy:
0.7966666666666666
[[189  11   3   1   0   0   1   0   0   1   0   0   1   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [ 10  32   1   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   1   4   6   1   0   2   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   1   8   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   1   1   2   1   1   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   2   0   1   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   2   0   0   1   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   1   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   2   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   1   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   1   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0
    0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0   1   0   0   0   0   0   0   0]]
             precision    recall  f1-score   support

          0       0.95      0.91      0.93       207
          1       0.73      0.73      0.73        44
          2       0.40      0.29      0.33        14
          3       0.42      0.89      0.57         9
          4       0.40      0.33      0.36         6
          5       0.50      0.33      0.40         3
          6       0.43      1.00      0.60         3
          7       0.00      0.00      0.00         2
          8       0.00      0.00      0.00         3
          9       0.00      0.00      0.00         0
         11       0.00      0.00      0.00         1
         12       0.00      0.00      0.00         0
         13       0.00      0.00      0.00         1
         15       0.00      0.00      0.00         0
         17       0.00      0.00      0.00         1
         19       0.00      0.00      0.00         2
         21       0.00      0.00      0.00         0
         29       0.00      0.00      0.00         0
         30       0.00      0.00      0.00         1
         32       0.00      0.00      0.00         0
         51       0.00      0.00      0.00         1
         57       0.00      0.00      0.00         1
        148       0.00      0.00      0.00         1

avg / total       0.81      0.80      0.80       300

